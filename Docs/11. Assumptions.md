# 11. Assumptions

Every system embeds assumptions â€” about its inputs, context, users, and goals. The Discovery Engine is no exception. This section articulates the key **epistemic, technical, and operational assumptions** that underpin its architecture, use, and interpretation.

These are not guarantees â€” they are **working hypotheses** that must be revisited as the system evolves.

---

## 11.1 Epistemic Assumptions

| Assumption                         | Implication                                                                 |
|------------------------------------|------------------------------------------------------------------------------|
| **Scientific language is structured enough** | That formal schema can capture core meanings from prose                    |
| **Knowledge is relational**        | That claims gain meaning from their connections to other concepts           |
| **Truth is provisional**           | That knowledge graphs represent *states of belief*, not final truth         |
| **Contradiction is informative**   | That detecting tension improves understanding, not undermines it            |
| **Evidence is anchorable**         | That textual provenance can reliably link claims to source context          |

These assumptions allow the system to treat publications as **inputs to a map**, not **statements of final reality**.

---

## 11.2 Technical Assumptions

| Assumption                         | Implication                                                                 |
|------------------------------------|------------------------------------------------------------------------------|
| **LLMs can extract structure**     | That transformer models, guided by templates, can yield usable artifacts     |
| **Templates can generalise**       | That a finite, field-aligned schema can cover most core scientific patterns |
| **Semantic embeddings are meaningful** | That vector distances reliably reflect conceptual similarity              |
| **Graph and tensor operations scale** | That CNM representations remain performant at large scale                 |

The system presumes sufficient compute and vector precision to support real-time interaction and synthesis across hundreds of thousands of artifacts.

---

## 11.3 User Assumptions

| Assumption                         | Implication                                                                 |
|------------------------------------|------------------------------------------------------------------------------|
| **Users can interpret graph outputs** | That scientists can navigate structured views of knowledge                 |
| **Users will engage critically**   | That human judgment complements agent output, not blindly follows it        |
| **Domain experts will provide feedback** | That synthesis improves with targeted human correction                 |
| **Transparency builds trust**      | That evidence-linked, interpretable interfaces foster legitimacy            |

The system is built for **humanâ€“AI co-navigation**, not full automation. It assumes curiosity, skepticism, and willingness to refine.

---

## 11.4 Corpus Assumptions

| Assumption                         | Implication                                                                 |
|------------------------------------|------------------------------------------------------------------------------|
| **Published papers contain extractable knowledge** | That most papers contain usable concepts, methods, or results          |
| **Language patterns reflect conceptual patterns** | That repeated phrasing corresponds to domain-relevant ideas           |
| **Citation and metadata are sufficient for context** | That provenance can often be inferred even when incomplete          |
| **Field-specific language is mappable** | That diverse terminologies can be aligned via embeddings + templates     |

These assumptions define the **epistemic surface area** that the system can meaningfully operate on.

---

## 11.5 Assumptions Under Review

Some assumptions are treated as **tentative** and subject to active testing:

| Assumption                         | Current Status                                                             |
|------------------------------------|----------------------------------------------------------------------------|
| **Graph centrality reflects importance** | Plausible, but depends on corpus biases                                   |
| **Gaps reflect unknowns**          | May reflect reporting practices, not knowledge absence                     |
| **All knowledge can be atomised**  | Not all insight is reducible to artifact form                              |
| **Templates converge**             | Assumed for tractability, but long-tail exceptions remain                  |

The system logs its own epistemic boundaries and flags **low-confidence assumptions** at runtime.

---

## 11.6 Assumptions Summary Table

| Domain             | Core Assumption                                      |
|--------------------|------------------------------------------------------|
| Epistemic          | Knowledge is relational, contextual, and evolving   |
| Technical          | Structure and scale can coexist                     |
| User               | Insight arises from interaction, not automation     |
| Corpus             | Language patterns encode extractable structure      |
| Architectural      | Feedback loops can stabilise a self-refining system |

---

> â˜‘ï¸ Visual prompt for napkin.ai:
>
> **Title**: â€œSystem Assumptions: What the Discovery Engine Presumesâ€
>
> - Four corner clusters:
>     - Epistemic Assumptions ğŸ§ 
>     - Technical Assumptions âš™ï¸
>     - User Assumptions ğŸ‘¤
>     - Corpus Assumptions ğŸ“š
>
> - Centre: â€œDiscovery Engineâ€ icon surrounded by a circular gradient labelled:  
>   â€œProvisional, Self-Monitoring, Evolvingâ€
>
> - Bottom label: â€œAssumptions â‰  Guarantees â€” They Define the System's Operating Beliefsâ€
